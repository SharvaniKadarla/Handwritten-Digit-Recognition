{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8M3c3reS7jx",
        "outputId": "b0bfcbca-12d2-4d2b-e76b-10d6cec7f5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3),  # Output: 26x26\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3), # Output: 24x24\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3), # Output: 22x22\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 22 * 22, 10)       # Fully connected layer for 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egVXuuMST1Hm",
        "outputId": "27e038d5-0a4b-451b-deb9-84fe938a6521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:**\n",
        "- model.py file is created and stored in the current working directory, which is the temporary runtime filesystem of the Colab virtual machine. By default, this is: /content/\n",
        "- To confirm list the files using: !ls /content/\n",
        "- Instead of creating a separate folder structure, we’ll define all the modules — such as `model.py`, `data_loader.py`, `train.py`, `evaluate.py`, and `utils.py` — directly within Google Colab using `%%writefile` in individual code cells to simulate separate Python files."
      ],
      "metadata": {
        "id": "-aNVyb-hUJ52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzfYUfZ3VdGi",
        "outputId": "bb04441a-e406-4993-a1b9-79895431098b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.py  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_loader.py\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_data_loader(batch_size=32):\n",
        "    train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
        "    return DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsOC11_CVgMj",
        "outputId": "4d2fa36e-904a-485f-bb17-9776a4ecd81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "\n",
        "def get_device():\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNtZGcbVk5r",
        "outputId": "c941abcb-f371-4e71-d61c-6e72a7ab03be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import sys\n",
        "from torch import save\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from model import ImageClassifier\n",
        "from data_loader import get_data_loader\n",
        "from utils import get_device\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(epochs=10, lr=1e-3, device=\"cpu\"):\n",
        "    loss_history = [] # List to track losses\n",
        "    model = ImageClassifier().to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    data_loader = get_data_loader()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Forward Pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Backward Pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        epoch_loss = total_loss / len(data_loader)\n",
        "        loss_history.append(epoch_loss) # Append epoch loss to history\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
        "\n",
        "    # torch.save(model.state_dict(), \"model_state.pt\")\n",
        "    with open(\"model_state.pt\", 'wb') as f:\n",
        "        save(model.state_dict(), f)\n",
        "\n",
        "    print(\"Training complete! Model saved as 'model_state.pt'.\")\n",
        "\n",
        "    # Plot loss curve\n",
        "    plt.plot(range(1, epochs + 1), loss_history, marker='o')\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid()\n",
        "    plt.savefig(\"training_loss_curve.png\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Device Setup\n",
        "    device = get_device()\n",
        "    train_model(epochs=5, device=device)  # Default: 5 epochs, but can also be 10 epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-IlDGNDVmYg",
        "outputId": "2443ed09-c200-4c44-a7b9-7ed66708e4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uHs1jdYVrJH",
        "outputId": "166123d1-0dae-4a1b-a953-8a0c4876d4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 9.91M/9.91M [00:00<00:00, 103MB/s]\n",
            "100% 28.9k/28.9k [00:00<00:00, 17.9MB/s]\n",
            "100% 1.65M/1.65M [00:00<00:00, 111MB/s]\n",
            "100% 4.54k/4.54k [00:00<00:00, 10.6MB/s]\n",
            "Epoch 1/5, Loss: 0.12433017870578915\n",
            "Epoch 2/5, Loss: 0.04544283072237546\n",
            "Epoch 3/5, Loss: 0.02886456973545525\n",
            "Epoch 4/5, Loss: 0.020408585228114194\n",
            "Epoch 5/5, Loss: 0.013985455428305432\n",
            "Training complete! Model saved as 'model_state.pt'.\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "import sys\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from model import ImageClassifier    # Assuming ImageClassifier is defined in train.py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(image_path, model_path=\"model_state.pt\", device=\"cpu\"):\n",
        "    # Load Model\n",
        "    model = ImageClassifier().to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    # Load and process the image\n",
        "    with ImageOps.invert(Image.open(image_path).convert('L')) as img:\n",
        "        img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        predicted_label = torch.argmax(output).item()\n",
        "\n",
        "    # Show image with prediction\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(f\"Predicted Label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUYKAeGgbWjH",
        "outputId": "e465ea91-4496-4ab6-d87a-baf040bb5ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import predict_image\n",
        "from utils import get_device\n",
        "\n",
        "predict_image(\"digit1.png\", device=get_device())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "hfK8KmA0bgJG",
        "outputId": "00ea2d09-7869-4637-99e8-3f05e598e7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 7\n"
          ]
        }
      ]
    }
  ]
}